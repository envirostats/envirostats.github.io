---
title: "Regular expressions and simple models"
subtitle: "EXGEN5449 - Winter 2020"
author: "Stefan Schreiber"
output:
  html_document:
    theme: paper
    highlight: pygments
    toc: true
    number_sections: true
    toc_depth: 3
    toc_float:
      collapsed: true
      smooth_scroll: true
---

<script>
$(document).ready(function() {
  $items = $('div#TOC li');
  $items.each(function(idx) {
    num_ul = $(this).parentsUntil('#TOC').length;
    $(this).css({'text-indent': num_ul * 10, 'padding-left': 0});
  });

});
</script>

```{css echo=FALSE}
.red { 
  color: red;
  padding-top: 0;
  margin-top: -20px;
  border-top-color: #f5f5f5;
}
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, comment = "#>")
```

# Regular expressions
As we saw yesterday regular expressions can save you a lot of time, if you put some effort into understanding how they work. They certainly look intimidating at first but you get used to it. For today we keep on working with regular expressions a bit more because I found a great R Studio Addin that helps you understanding them and get a taste for what is possible! The package is currently only available on GitHub. In order to download packages from GitHub you first need to download the `devtools` package. Once you have downloaded it, you can install packages straight from GitHub. The package we will using is called regexplain and can be found [here](https://github.com/gadenbuie/regexplain). Have a look at the README file. To install the package run:
```{r eval=FALSE}
devtools::install_github("gadenbuie/regexplain")
```

Now you will have `REGEXPLAIN` in your `Addins` drop down menu (below the `Tools` menu). Another great resource for testing your regular expressions are these two website: https://regex101.com/ and https://www.regular-expressions.info/ 

I also wanted to share with you the regex example I showed you yesterday. Instead of sending or downloading CSV files, you could also read out the data frame you are working with using the `dput()` function. Then you can simply copy/paste the output into an email and send it to your collaborator for example. This also very helpful when you ask a question on those QA sites such as [StackOverflow](https://stackoverflow.com/) as they always want a reproducible example but at the same time will not download any files on there own computers. Once you share the `dput()` output, the recipient can simply copy/paste it into their own R console and recreate your data frame that way. Below I did the same. Simply copy/paste those two blocks of code into your console and you have those data sets ready.    

```{r message = FALSE}
require(tidyverse)

d1 <- structure(list(Treatment = structure(1:3, .Label = c("a", "b", 
"c"), class = "factor"), Height_7days = c(0.241756922, 0.017613771, 
0.913951358), Height.14days = c(0.557475118, 0.115967094, 0.276483941
), Height21days = c(0.882937228, 0.664116205, 0.110760574), Weight_7days = c(0.014404525, 
0.591611048, 0.365071975), Weight..14days = c(0.365071975, 0.46561814, 
0.943144072), Weight_21days = c(0.420476422, 0.86572502, 0.911250316
)), class = "data.frame", row.names = c(NA, -3L))

d2 <- structure(list(Treatment = c("a", "b", "c"), Height_7days = c(0.241756922, 
0.017613771, 0.913951358), `Height 14days` = c(0.557475118, 0.115967094, 
0.276483941), Height21days = c(0.882937228, 0.664116205, 0.110760574
), Weight_7days = c(0.014404525, 0.591611048, 0.365071975), `Weight  14days` = c(0.365071975, 
0.46561814, 0.943144072), Weight_21days = c(0.420476422, 0.86572502, 
0.911250316)), class = c("spec_tbl_df", "tbl_df", "tbl", "data.frame"
), row.names = c(NA, -3L), spec = structure(list(cols = list(
    Treatment = structure(list(), class = c("collector_character", 
    "collector")), Height_7days = structure(list(), class = c("collector_double", 
    "collector")), `Height 14days` = structure(list(), class = c("collector_double", 
    "collector")), Height21days = structure(list(), class = c("collector_double", 
    "collector")), Weight_7days = structure(list(), class = c("collector_double", 
    "collector")), `Weight  14days` = structure(list(), class = c("collector_double", 
    "collector")), Weight_21days = structure(list(), class = c("collector_double", 
    "collector"))), default = structure(list(), class = c("collector_guess", 
"collector")), skip = 1), class = "col_spec"))

d1

d2

# the regex below in the extract() function is universal enough to match both scenarios (read.csv and read_csv)
# there are also shorthand versions of this regex but I use this one as it is more clear to me
# this is where I got the idea from: https://stackoverflow.com/questions/25925556/gather-multiple-sets-of-columns
# see also ?regex 

# run each line individually to see what the function are doing
d1 %>%  pivot_longer(names_to =  "key", values_to = "value", - Treatment) %>% 
  extract(key, c("parameter", "Days"), "([[:alpha:]]+)[[:space:][:punct:]]*([[:digit:]]+)") %>%
  pivot_wider(names_from = parameter, values_from = value)

d2 %>%  pivot_longer(names_to =  "key", values_to = "value", - Treatment) %>% 
  extract(key, c("parameter", "Days"), "([[:alpha:]]+)[[:space:][:punct:]]*([[:digit:]]+)") %>%
  pivot_wider(names_from = parameter, values_from = value)

```

Here is another regex example how to clean up messy files (example data from Tomas):

```{r message=F}
require(tidyverse)
require(lubridate)

d3 <- structure(list(X1 = c("01-01-01", "01-02-01", "01-03-01", "01-04-01", 
"01-05-01", "01-06-01", "01-07-01", "01-08-01", "01-09-01", "01-10-01", 
"01-11-01", "01-12-01", "01-01-02", "01-02-02", "01-03-02", "01-04-02", 
"01-05-02", "01-06-02", "01-07-02", "01-08-02", "01-09-02"), 
    NAICS = c("11", "11A", "22", "23C", "31-33", "31-33", "31-33", 
    "31-33", "31-33", "31-33", "31-33", "41", "51", "61", "51C", 
    "71", "81", "91", "91", "91", "91"), Persons = c("100F", 
    "120A", "96", "19", "89", "54", "81", "92", "86", "57B", 
    "76", "5", "91", "7", "30", "77", "22", "32", "77", "48", 
    "32"), Wages = c("..", "N/A", "120", "80", "na", NA, "Na", 
    "30", "nA", "15", "17", "83", "36", "N/A", "43", "..", "14", 
    "11", "N/A", "..", "77")), class = c("spec_tbl_df", "tbl_df", 
"tbl", "data.frame"), row.names = c(NA, -21L), spec = structure(list(
    cols = list(X1 = structure(list(), class = c("collector_character", 
    "collector")), NAICS = structure(list(), class = c("collector_character", 
    "collector")), Persons = structure(list(), class = c("collector_character", 
    "collector")), Wages = structure(list(), class = c("collector_character", 
    "collector"))), default = structure(list(), class = c("collector_guess", 
    "collector")), skip = 1), class = "col_spec"))
```

Using `str_view()` we can see what the regex is matching. Then we can either `str_extract()` or `str_replace()`. If there is one simply pattern of what you want to keep, then use `str_extract()`. On the other hand sometimes it makes more sense to use `str_replace` (see example below).

```{r eval=F}
str_view(d3$NAICS, "\\d+") # see the matches
str_extract(d3$NAICS, "\\d+") # we can use str_extract here to pull out what we want

# we can apply the same logic here:
str_view(d3$Persons, "\\d+") # see the matches
str_extract(d3$Persons, "\\d+") # we can use str_extract here to pull out what we want

# finding various types of NAs. Here it's better to identify a common pattern and replace it with nothing
str_view(d3$Wages, "\\.+|[nN/aA]+") # see the matches
str_replace(d3$Wages, "\\.+|[nN/aA]+", "")
```

Now this works for this data set, so let's proceed and fix it up.

```{r}
# clean data
d3 %>% 
  rename(Date = X1) %>%
  # first I change `Date` to an actual date object using `ymd()` from the `lubridate` package
  mutate(Date = ymd(Date),
         NAICS = str_extract(NAICS, "\\d+"),
         Persons = str_extract(Persons, "\\d+"),
         Wages = str_replace(Wages, "\\.+|[nN/aA]+", "")) %>%
  # mutate_at will apply a function to specific variables
  # in this case we need to change from `character` to `double` (or numeric)
  # see `?mutate_at` for details
  mutate_at(.vars = vars(NAICS, Persons, Wages), .funs = as.double) %>% 
  # with `print` you can change how many rows you want to see (default is 10)
  print(n = 40)

```

We also talked about the `fill()` function from the `dplyr` package. Very handy function! Put it in your tool box! Here is an example:

```{r}
(d4 <- tibble(Country = c("Western Canada", NA, NA, "Central Canada", NA, NA),
              Province = c("BC", "AB", "SK","MB", "ON", "QC")))

d4 %>% 
  fill(Country)

```

Now I want to share another great data set with you. You can find it in the `gapminder` package:

```{r}
require(gapminder)
```

To change things up a bit let's watch a quick movie about this data set: https://www.youtube.com/watch?v=jbkSRLYSojo

The gapminder data set is a subset of the data presented in the video. Now, it's your turn again! Take the data set and turn it upside down. 


# Analysis of variance
```{r}
m1 <- aov(lifeExp ~ continent, data = gapminder)
summary(m1) # Significant continent effect

# emmeans package great for doing posthoc comparisons
require(emmeans)

(mean_comparisons <- emmeans(m1, "continent"))
(tukey_comparisons <- CLD(mean_comparisons, Letters = letters))
tukey_comparisons$.group2 <- trimws(tukey_comparisons$.group)

ggplot(tukey_comparisons, aes(x = continent, y = emmean)) + 
  geom_pointrange(aes(ymin = lower.CL, ymax = upper.CL)) + 
  geom_text(aes(x = continent, y = upper.CL + 2, label = .group2)) +
  labs(x = "Continent", y = "Mean Life Expectancy")

ggplot(tukey_comparisons, aes(x = continent, y = emmean)) + 
  geom_col(fill = "grey60") + 
  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.25) +
  geom_text(aes(x = continent, y = upper.CL + 3, label = .group2)) +
  labs(x = "Continent", y = "Mean Life Expectancy")

```


# Linear regression
```{r}
gapminder %>% 
  filter(continent == "Europe") -> europe 
  
m2 <- lm(lifeExp ~ gdpPercap, europe)
m2

summary(m2)

ggplot(europe, aes(gdpPercap, lifeExp)) + 
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x = "GDP per capita", y = "Life Expectancy")
```
```{r}
# predict some new data from the model
new_data <- tibble(gdpPercap = c(20000, 30000, 40000, 50000))
new_data

predict(m2, new_data, interval = "prediction")

```

# Multiple models
Also check out the chapter [Many Models](https://r4ds.had.co.nz/many-models.html) in the [R for Data Science](https://r4ds.had.co.nz/) book.

```{r}
gapminder %>%
  group_by(country, continent) %>% 
  nest() -> gapm_country
gapm_country

# And then run the lm function only once!
gapm_country %>% 
  mutate(model = purrr::map(data, ~ lm(lifeExp ~ year, data = .x))) -> country_model
country_model

# Using the `tidy()` function from the `broom` package we can see each model result in one data frame!
country_model %>% 
  mutate(tidy_models = purrr::map(model, broom::tidy)) %>% # replace with `broom::augment` and `broom::glance`
  unnest(tidy_models) -> model_summary
model_summary
```

```{r eval = F}
write_csv(model_summary, "model_summary")
```